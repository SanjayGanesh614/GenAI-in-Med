{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUZhQdPD8QsDD3451JZxsC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VqWJVJ01yl1N"},"outputs":[],"source":["import tenseal as ts\n","import torch\n","from model import SimpleNN\n","\n","\n","def encrypted_inference(model, X_samples, scaler):\n","    context = ts.context(\n","        ts.SCHEME_TYPE.CKKS,\n","        poly_modulus_degree=8192,\n","        coeff_mod_bit_sizes=[60, 40, 40, 60]\n","    )\n","    context.generate_galois_keys()\n","    context.global_scale = 2**40\n","\n","    model.eval()\n","    for i, sample in enumerate(X_samples):\n","        encrypted_sample = ts.ckks_vector(context, sample)\n","        decrypted = torch.tensor(encrypted_sample.decrypt())\n","        output = model(decrypted.unsqueeze(0))\n","        pred = torch.argmax(output, dim=1).item()\n","        print(f\"Sample {i+1} âžœ Predicted: {pred}\")\n"]}]}